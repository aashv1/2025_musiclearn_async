{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12334032,"sourceType":"datasetVersion","datasetId":7774903}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:46:56.509783Z","iopub.execute_input":"2025-06-30T20:46:56.509943Z","iopub.status.idle":"2025-06-30T20:46:58.232119Z","shell.execute_reply.started":"2025-06-30T20:46:56.509928Z","shell.execute_reply":"2025-06-30T20:46:58.231403Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/amuxdata/test_data.parquet\n/kaggle/input/amuxdata/add_event.parquet\n/kaggle/input/amuxdata/685404e30cfdb_submission_template.csv\n/kaggle/input/amuxdata/offer_metadata.parquet\n/kaggle/input/amuxdata/add_trans.parquet\n/kaggle/input/amuxdata/train_data.parquet\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 1: Imports and Data Loading\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nfrom sklearn.preprocessing import StandardScaler\n\n# Load your data (example: train and test)\ndf_train = pd.read_parquet('/kaggle/input/amuxdata/train_data.parquet')\ndf_test = pd.read_parquet('/kaggle/input/amuxdata/test_data.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:46:58.233754Z","iopub.execute_input":"2025-06-30T20:46:58.234021Z","iopub.status.idle":"2025-06-30T20:47:22.338066Z","shell.execute_reply.started":"2025-06-30T20:46:58.234004Z","shell.execute_reply":"2025-06-30T20:47:22.337444Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Cell 2: Basic EDA\n\nprint(df_train.head())\nprint(df_train.info())\nprint(df_train.describe())\nprint(\"\\nMissing values:\\n\", df_train.isnull().sum())\nprint(\"\\nDuplicates:\", df_train.duplicated().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:47:22.338925Z","iopub.execute_input":"2025-06-30T20:47:22.339505Z","iopub.status.idle":"2025-06-30T20:48:13.430414Z","shell.execute_reply.started":"2025-06-30T20:47:22.339477Z","shell.execute_reply":"2025-06-30T20:48:13.429639Z"}},"outputs":[{"name":"stdout","text":"                                               id1      id2        id3  \\\n0  1366776_189706075_16-23_2023-11-02 22:22:00.042  1366776  189706075   \n1      1366776_89227_16-23_2023-11-01 23:51:24.999  1366776      89227   \n2      1366776_35046_16-23_2023-11-01 00:30:59.797  1366776      35046   \n3    1366776_6275451_16-23_2023-11-02 22:21:32.261  1366776    6275451   \n4      1366776_78053_16-23_2023-11-02 22:21:34.799  1366776      78053   \n\n                       id4         id5  y   f1    f2    f3    f4  ...  f357  \\\n0  2023-11-02 22:22:00.042  2023-11-02  0  1.0  None  None  None  ...  None   \n1  2023-11-01 23:51:24.999  2023-11-01  0  1.0  None  None  None  ...  None   \n2  2023-11-01 00:30:59.797  2023-11-01  0  1.0  None  None  None  ...  None   \n3  2023-11-02 22:21:32.261  2023-11-02  0  1.0  None  None  None  ...  None   \n4  2023-11-02 22:21:34.799  2023-11-02  0  1.0  None  None  None  ...  None   \n\n      f358 f359  f360   f361 f362               f363    f364 f365  \\\n0  -9999.0  0.0  None   28.0  0.0                0.0   337.0  0.0   \n1     None  0.0  None   87.0  0.0                0.0  1010.0  2.0   \n2     None  0.0  None   23.0  0.0                0.0  1010.0  2.0   \n3  -9999.0  0.0  None  277.0  1.0  0.003610108303249   337.0  0.0   \n4  -9999.0  0.0  None  359.0  0.0                0.0   337.0  0.0   \n\n                 f366  \n0                 0.0  \n1  0.0019801980198019  \n2  0.0019801980198019  \n3                 0.0  \n4                 0.0  \n\n[5 rows x 372 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 770164 entries, 0 to 770163\nColumns: 372 entries, id1 to f366\ndtypes: object(372)\nmemory usage: 2.1+ GB\nNone\n                                                id1      id2     id3  \\\ncount                                        770164   770164  770164   \nunique                                       770164    46550     757   \ntop     1901215_95807_16-23_2023-11-01 11:01:33.086  1396352   92636   \nfreq                                              1      510    2446   \n\n                            id4         id5       y      f1      f2      f3  \\\ncount                    770164      770164  770164  278506  322972  108562   \nunique                   763371           3       2      82      88      74   \ntop     2023-11-01 16:04:43.564  2023-11-01       0    13.0     9.0     1.0   \nfreq                          5      301698  733113   42443   33756   19425   \n\n           f4  ...    f357     f358    f359 f360    f361    f362    f363  \\\ncount   68869  ...  587734   628173  727175  232  654412  654412  654412   \nunique     65  ...    2305     2150       2    1    1951     110    8398   \ntop       1.0  ...     0.0  -9999.0     0.0  1.0     1.0     0.0     0.0   \nfreq    14848  ...   13352    53759  725345  232   42543  418293  418293   \n\n          f364    f365    f366  \ncount   661850  661850  661850  \nunique    3893     505   18084  \ntop       51.0     0.0     0.0  \nfreq      6773  205968  205968  \n\n[4 rows x 372 columns]\n\nMissing values:\n id1          0\nid2          0\nid3          0\nid4          0\nid5          0\n         ...  \nf362    115752\nf363    115752\nf364    108314\nf365    108314\nf366    108314\nLength: 372, dtype: int64\n\nDuplicates: 0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"print(df_train['id2'].dtype)  # Check dtype\n\n# Try converting to numeric\ndf_train['id2'] = pd.to_numeric(df_train['id2'], errors='coerce')\nprint(df_train['id2'].dtype)  # Should now be int or float","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:48:13.431293Z","iopub.execute_input":"2025-06-30T20:48:13.431642Z","iopub.status.idle":"2025-06-30T20:48:13.772868Z","shell.execute_reply.started":"2025-06-30T20:48:13.431615Z","shell.execute_reply":"2025-06-30T20:48:13.772031Z"}},"outputs":[{"name":"stdout","text":"object\nint64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Convert columns that look numeric but are object to numeric dtype\nfor col in df_train.columns:\n    if df_train[col].dtype == 'object':\n        try:\n            df_train[col] = pd.to_numeric(df_train[col])\n            df_test[col] = pd.to_numeric(df_test[col])\n        except Exception:\n            pass  # If conversion fails, keep as object\n\n# Now identify categorical/object columns (masked features)\ncat_cols = df_train.select_dtypes(include=['object']).columns.tolist()\nprint(\"Categorical columns:\", cat_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:48:13.773720Z","iopub.execute_input":"2025-06-30T20:48:13.774091Z","iopub.status.idle":"2025-06-30T20:49:39.704364Z","shell.execute_reply.started":"2025-06-30T20:48:13.774066Z","shell.execute_reply":"2025-06-30T20:49:39.703589Z"}},"outputs":[{"name":"stdout","text":"Categorical columns: ['id1', 'id4', 'id5', 'f42', 'f50', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f354']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Cell 3: Feature Engineering for Masked Features\n\n# Identify categorical/object columns (masked features)\ncat_cols = df_train.select_dtypes(include=['object']).columns.tolist()\nprint(\"Categorical columns:\", cat_cols)\n\n# Frequency encode all at once\ndef freq_encode(df_train, df_test, cols):\n    train_encoded = pd.DataFrame(index=df_train.index)\n    test_encoded = pd.DataFrame(index=df_test.index)\n    \n    for col in cols:\n        freq = df_train[col].value_counts()\n        train_encoded[col + '_freq'] = df_train[col].map(freq)\n        test_encoded[col + '_freq'] = df_test[col].map(freq)\n\n    return train_encoded, test_encoded\n\ntrain_freq, test_freq = freq_encode(df_train, df_test, cat_cols)\n\n# Drop original masked columns and add new ones efficiently\ndf_train = pd.concat([df_train.drop(columns=cat_cols), train_freq], axis=1)\ndf_test = pd.concat([df_test.drop(columns=cat_cols), test_freq], axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:49:39.705157Z","iopub.execute_input":"2025-06-30T20:49:39.705405Z","iopub.status.idle":"2025-06-30T20:49:49.303408Z","shell.execute_reply.started":"2025-06-30T20:49:39.705381Z","shell.execute_reply":"2025-06-30T20:49:49.302841Z"}},"outputs":[{"name":"stdout","text":"Categorical columns: ['id1', 'id4', 'id5', 'f42', 'f50', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f354']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Clean df_test\ndf_test_clean = df_test.copy()\n\n# Convert to numeric, coerce errors (e.g., strings → NaN)\ndf_test_clean = df_test_clean.apply(pd.to_numeric, errors='coerce')\n\n# Fill missing values (you can also use imputation or other methods)\ndf_test_clean = df_test_clean.fillna(0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:50:51.826957Z","iopub.execute_input":"2025-06-30T20:50:51.827213Z","iopub.status.idle":"2025-06-30T20:50:54.176197Z","shell.execute_reply.started":"2025-06-30T20:50:51.827196Z","shell.execute_reply":"2025-06-30T20:50:54.175291Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2575094626.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fill missing values (you can also use imputation or other methods)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf_test_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: StandardScaler.transform() missing 1 required positional argument: 'X'"],"ename":"TypeError","evalue":"StandardScaler.transform() missing 1 required positional argument: 'X'","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"# Cell 4: Prepare Data for Modeling\n\n# Replace with your actual target column name\nTARGET = 'y'  # Example: replace with actual target\n\nX = df_train.drop(columns=[TARGET])\ny = df_train[TARGET]\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(np.isnan(X_train).sum(), np.isinf(X_train).sum())\nprint(np.isnan(X_val).sum(), np.isinf(X_val).sum())\n\nX_train = np.nan_to_num(X_train, nan=0.0, posinf=0.0, neginf=0.0)\nX_val = np.nan_to_num(X_val, nan=0.0, posinf=0.0, neginf=0.0)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\ndf_test_scaled = scaler.transform(df_test_clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:52:30.502205Z","iopub.execute_input":"2025-06-30T20:52:30.502901Z","iopub.status.idle":"2025-06-30T20:52:44.790910Z","shell.execute_reply.started":"2025-06-30T20:52:30.502877Z","shell.execute_reply":"2025-06-30T20:52:44.790094Z"}},"outputs":[{"name":"stdout","text":"id2               0\nid3               0\nf1           393540\nf2           357854\nf3           529171\n              ...  \nf54_freq     203524\nf55_freq     203524\nf56_freq     203524\nf57_freq     346312\nf354_freq    113474\nLength: 371, dtype: int64 id2          0\nid3          0\nf1           0\nf2           0\nf3           0\n            ..\nf54_freq     0\nf55_freq     0\nf56_freq     0\nf57_freq     0\nf354_freq    0\nLength: 371, dtype: int64\nid2               0\nid3               0\nf1            98118\nf2            89338\nf3           132431\n              ...  \nf54_freq      50943\nf55_freq      50943\nf56_freq      50943\nf57_freq      86580\nf354_freq     28517\nLength: 371, dtype: int64 id2          0\nid3          0\nf1           0\nf2           0\nf3           0\n            ..\nf54_freq     0\nf55_freq     0\nf56_freq     0\nf57_freq     0\nf354_freq    0\nLength: 371, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n  warnings.warn(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(y_train.unique())  # should be [0, 1]\nprint(y_val.unique())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:53:19.264399Z","iopub.execute_input":"2025-06-30T20:53:19.264978Z","iopub.status.idle":"2025-06-30T20:53:19.276858Z","shell.execute_reply.started":"2025-06-30T20:53:19.264948Z","shell.execute_reply":"2025-06-30T20:53:19.276027Z"}},"outputs":[{"name":"stdout","text":"[0 1]\n[0 1]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Choose device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Convert numpy arrays to torch tensors and move to CPU first\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\nX_val_tensor = torch.tensor(X_val, dtype=torch.float32)\ny_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).unsqueeze(1)\n\n\n# Create DataLoaders\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\nval_dataset = TensorDataset(X_val_tensor, y_val_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=256)\n\n# Define the model\nclass SimpleNN(nn.Module):\n    def __init__(self, input_dim):\n        super(SimpleNN, self).__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.LeakyReLU(),\n            nn.Linear(64, 32),\n            nn.LeakyReLU(),\n            nn.Linear(32, 1)\n        )\n    def forward(self, x):\n        return self.net(x)\n\n# Instantiate and move model to device\nmodel = SimpleNN(X_train.shape[1]).to(device)\n\n# Loss and optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# Training loop\nfor epoch in range(10):\n    model.train()\n    for xb, yb in train_loader:\n        xb, yb = xb.to(device), yb.to(device)  # Move batch to GPU\n        optimizer.zero_grad()\n        preds = model(xb)  # No sigmoid here!\n        loss = criterion(preds, yb)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n\n\n    # Validation\n    model.eval()\n    with torch.no_grad():\n        val_preds = model(X_val_tensor.to(device))\n        val_loss = criterion(val_preds, y_val_tensor.to(device))\n        print(f\"Epoch {epoch+1}, Val Loss: {val_loss.item():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:53:20.980400Z","iopub.execute_input":"2025-06-30T20:53:20.981031Z","iopub.status.idle":"2025-06-30T20:58:05.688544Z","shell.execute_reply.started":"2025-06-30T20:53:20.981001Z","shell.execute_reply":"2025-06-30T20:58:05.687673Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Val Loss: 0.0965\nEpoch 2, Val Loss: 0.0897\nEpoch 3, Val Loss: 0.0888\nEpoch 4, Val Loss: 0.0865\nEpoch 5, Val Loss: 0.0861\nEpoch 6, Val Loss: 0.0846\nEpoch 7, Val Loss: 0.0843\nEpoch 8, Val Loss: 0.0839\nEpoch 9, Val Loss: 0.0837\nEpoch 10, Val Loss: 0.0847\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# For final predictions (e.g., test set)\nmodel.eval()\nwith torch.no_grad():\n    test_tensor = torch.tensor(df_test_scaled, dtype=torch.float32).to(device)\n    test_logits = model(test_tensor)\n    test_pred = torch.sigmoid(test_logits).cpu().numpy().flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:58:05.689697Z","iopub.execute_input":"2025-06-30T20:58:05.690342Z","iopub.status.idle":"2025-06-30T20:58:05.896362Z","shell.execute_reply.started":"2025-06-30T20:58:05.690319Z","shell.execute_reply":"2025-06-30T20:58:05.895572Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Cell 6: Validation and Prediction\n\nval_pred = torch.sigmoid(model(X_val_tensor.to(device))).cpu().detach().numpy().flatten()\n\nauc = roc_auc_score(y_val, val_pred)\nprint(f\"Validation ROC-AUC: {auc:.4f}\")\n\n# Predict on test set (if target is available)\n# test_pred = model.predict(df_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:58:05.897161Z","iopub.execute_input":"2025-06-30T20:58:05.897382Z","iopub.status.idle":"2025-06-30T20:58:06.021632Z","shell.execute_reply.started":"2025-06-30T20:58:05.897365Z","shell.execute_reply":"2025-06-30T20:58:06.020763Z"}},"outputs":[{"name":"stdout","text":"Validation ROC-AUC: 0.9354\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/amuxdata/685404e30cfdb_submission_template.csv')\nsubmission['pred'] = test_pred\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file saved as submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:58:06.023433Z","iopub.execute_input":"2025-06-30T20:58:06.023680Z","iopub.status.idle":"2025-06-30T20:58:08.072025Z","shell.execute_reply.started":"2025-06-30T20:58:06.023665Z","shell.execute_reply":"2025-06-30T20:58:08.071352Z"}},"outputs":[{"name":"stdout","text":"Submission file saved as submission.csv\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(\"submission.shape:\", submission.shape)\nprint(\"test_pred.shape:\", test_pred.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:58:08.072747Z","iopub.execute_input":"2025-06-30T20:58:08.072960Z","iopub.status.idle":"2025-06-30T20:58:08.077057Z","shell.execute_reply.started":"2025-06-30T20:58:08.072944Z","shell.execute_reply":"2025-06-30T20:58:08.076470Z"}},"outputs":[{"name":"stdout","text":"submission.shape: (369301, 5)\ntest_pred.shape: (369301,)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print(test_pred[:10])\nprint(np.isnan(test_pred).sum(), np.isinf(test_pred).sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:58:08.077745Z","iopub.execute_input":"2025-06-30T20:58:08.077981Z","iopub.status.idle":"2025-06-30T20:58:08.091209Z","shell.execute_reply.started":"2025-06-30T20:58:08.077959Z","shell.execute_reply":"2025-06-30T20:58:08.090514Z"}},"outputs":[{"name":"stdout","text":"[0.02200713 0.00231058 0.98975116 0.06414712 0.06035268 0.05715678\n 0.02846122 0.0198497  0.14258733 0.04859566]\n0 0\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"print(test_logits[:10])\nprint(torch.isnan(test_logits).sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T20:58:08.092067Z","iopub.execute_input":"2025-06-30T20:58:08.092311Z","iopub.status.idle":"2025-06-30T20:58:08.205805Z","shell.execute_reply.started":"2025-06-30T20:58:08.092295Z","shell.execute_reply":"2025-06-30T20:58:08.205176Z"}},"outputs":[{"name":"stdout","text":"tensor([[-3.7941],\n        [-6.0679],\n        [ 4.5703],\n        [-2.6803],\n        [-2.7453],\n        [-2.8031],\n        [-3.5303],\n        [-3.8995],\n        [-1.7940],\n        [-2.9744]], device='cuda:0')\ntensor(0, device='cuda:0')\n","output_type":"stream"}],"execution_count":19}]}